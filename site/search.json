{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"pydynox","text":"<p>A fast DynamoDB ORM for Python with a Rust core.</p> <p>pydynox lets you work with DynamoDB using Python classes instead of raw dictionaries. The heavy lifting (serialization, deserialization) happens in Rust, so it's fast.</p>","path":["pydynox"],"tags":[]},{"location":"#key-features","level":2,"title":"Key features","text":"<ul> <li>Fast serialization - Rust handles the heavy lifting</li> <li>Simple API - Define models like Django or SQLAlchemy</li> <li>Type hints - Full IDE support with autocomplete</li> <li>Rate limiting - Control throughput to avoid throttling</li> <li>Lifecycle hooks - Run code before/after operations</li> <li>TTL support - Auto-delete items after expiration</li> <li>Pydantic integration - Use your existing Pydantic models</li> </ul>","path":["pydynox"],"tags":[]},{"location":"#getting-started","level":2,"title":"Getting started","text":"","path":["pydynox"],"tags":[]},{"location":"#installation","level":3,"title":"Installation","text":"pipuv <pre><code>pip install pydynox\n</code></pre> <pre><code>uv add pydynox\n</code></pre> <p>For Pydantic support:</p> <pre><code>pip install pydynox[pydantic]\n</code></pre>","path":["pydynox"],"tags":[]},{"location":"#define-a-model","level":3,"title":"Define a model","text":"<p>A model is a Python class that maps to a DynamoDB table. You define attributes with their types, and pydynox handles the rest:</p> basic_model.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import BooleanAttribute, NumberAttribute, StringAttribute\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    sk = StringAttribute(range_key=True)\n    name = StringAttribute()\n    age = NumberAttribute(default=0)\n    active = BooleanAttribute(default=True)\n</code></pre>","path":["pydynox"],"tags":[]},{"location":"#crud-operations","level":3,"title":"CRUD operations","text":"<p>Once you have a model, you can create, read, update, and delete items:</p> crud_operations.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import NumberAttribute, StringAttribute\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    sk = StringAttribute(range_key=True)\n    name = StringAttribute()\n    age = NumberAttribute(default=0)\n\n\n# Create\nuser = User(pk=\"USER#123\", sk=\"PROFILE\", name=\"John\", age=30)\nuser.save()\n\n# Read\nuser = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nif user:\n    print(user.name)  # John\n\n# Update - full\nuser.name = \"Jane\"\nuser.save()\n\n# Update - partial\nuser.update(name=\"Jane\", age=31)\n\n# Delete\nuser.delete()\n</code></pre> <p>That's it! You're now using DynamoDB with a clean, typed API.</p>","path":["pydynox"],"tags":[]},{"location":"#whats-next","level":2,"title":"What's next?","text":"<p>Now that you have the basics, explore these guides:</p> Guide Description Models Learn about attributes, keys, and defaults CRUD operations More on create, read, update, delete Batch operations Work with multiple items at once Transactions All-or-nothing operations Rate limiting Control throughput Lifecycle hooks Run code before/after operations TTL Auto-delete items Pydantic Use Pydantic models","path":["pydynox"],"tags":[]},{"location":"getting-started/","level":1,"title":"Getting started","text":"<p>This guide walks you through installing pydynox and creating your first model. By the end, you'll have a working DynamoDB model with CRUD operations.</p>","path":["Getting started"],"tags":[]},{"location":"getting-started/#key-features","level":2,"title":"Key features","text":"<ul> <li>Install with pip or uv</li> <li>Define models with typed attributes</li> <li>CRUD operations with simple methods</li> <li>Local development with DynamoDB Local</li> </ul>","path":["Getting started"],"tags":[]},{"location":"getting-started/#installation","level":2,"title":"Installation","text":"pipuv <pre><code>pip install pydynox\n</code></pre> <pre><code>uv add pydynox\n</code></pre> <p>To verify the installation:</p> <pre><code>import pydynox\nprint(pydynox.__version__)\n</code></pre>","path":["Getting started"],"tags":[]},{"location":"getting-started/#your-first-model","level":2,"title":"Your first model","text":"<p>Let's create a simple User model. A model is a Python class that represents items in a DynamoDB table.</p> basic_model.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import BooleanAttribute, NumberAttribute, StringAttribute\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    sk = StringAttribute(range_key=True)\n    name = StringAttribute()\n    age = NumberAttribute(default=0)\n    active = BooleanAttribute(default=True)\n</code></pre> <p>Here's what each part does:</p> <ul> <li><code>class Meta</code> - Configuration for the model. <code>table</code> is the DynamoDB table name.</li> <li><code>pk = StringAttribute(hash_key=True)</code> - The partition key. Every item needs one.</li> <li><code>sk = StringAttribute(range_key=True)</code> - The sort key. Optional, but useful for complex access patterns.</li> <li>Other attributes - Regular fields with their types and optional defaults.</li> </ul>","path":["Getting started"],"tags":[]},{"location":"getting-started/#basic-operations","level":2,"title":"Basic operations","text":"<p>Now let's use the model to work with DynamoDB:</p> crud_operations.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import NumberAttribute, StringAttribute\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    sk = StringAttribute(range_key=True)\n    name = StringAttribute()\n    age = NumberAttribute(default=0)\n\n\n# Create\nuser = User(pk=\"USER#123\", sk=\"PROFILE\", name=\"John\", age=30)\nuser.save()\n\n# Read\nuser = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nif user:\n    print(user.name)  # John\n\n# Update - full\nuser.name = \"Jane\"\nuser.save()\n\n# Update - partial\nuser.update(name=\"Jane\", age=31)\n\n# Delete\nuser.delete()\n</code></pre>","path":["Getting started"],"tags":[]},{"location":"getting-started/#create","level":3,"title":"Create","text":"<p>Instantiate your model and call <code>save()</code>:</p> <pre><code>user = User(pk=\"USER#123\", sk=\"PROFILE\", name=\"John\", age=30)\nuser.save()\n</code></pre>","path":["Getting started"],"tags":[]},{"location":"getting-started/#read","level":3,"title":"Read","text":"<p>Use <code>get()</code> with the key attributes:</p> <pre><code>user = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nif user:\n    print(user.name)\n</code></pre>","path":["Getting started"],"tags":[]},{"location":"getting-started/#update","level":3,"title":"Update","text":"<p>Change attributes and save, or use <code>update()</code> for partial updates:</p> <pre><code># Full update\nuser.name = \"Jane\"\nuser.save()\n\n# Partial update\nuser.update(name=\"Jane\", age=31)\n</code></pre>","path":["Getting started"],"tags":[]},{"location":"getting-started/#delete","level":3,"title":"Delete","text":"<p>Call <code>delete()</code> on an instance:</p> <pre><code>user.delete()\n</code></pre>","path":["Getting started"],"tags":[]},{"location":"getting-started/#configuration","level":2,"title":"Configuration","text":"<p>The <code>Meta</code> class configures how your model connects to DynamoDB:</p> <pre><code>class User(Model):\n    class Meta:\n        table = \"users\"           # Required - table name\n        region = \"us-east-1\"      # Optional - AWS region\n        endpoint_url = None       # Optional - for local testing\n</code></pre>","path":["Getting started"],"tags":[]},{"location":"getting-started/#local-development","level":2,"title":"Local development","text":"<p>For local testing, use DynamoDB Local. It's a downloadable version of DynamoDB that runs on your machine.</p> <p>Start DynamoDB Local (using Docker):</p> <pre><code>docker run -p 8000:8000 amazon/dynamodb-local\n</code></pre> <p>Then point your model to it:</p> <pre><code>class User(Model):\n    class Meta:\n        table = \"users\"\n        endpoint_url = \"http://localhost:8000\"\n</code></pre> <p>Tip</p> <p>DynamoDB Local is great for development and testing. You don't need AWS credentials, and you won't accidentally modify production data.</p>","path":["Getting started"],"tags":[]},{"location":"getting-started/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you have the basics working:</p> <ul> <li>Models - Learn about all attribute types and options</li> <li>Batch operations - Work with multiple items efficiently</li> <li>Rate limiting - Control throughput to avoid throttling</li> <li>Lifecycle hooks - Add validation and logging</li> </ul>","path":["Getting started"],"tags":[]},{"location":"guides/01-models/","level":1,"title":"Models","text":"<p>Models define the structure of your DynamoDB items.</p>","path":["Models"],"tags":[]},{"location":"guides/01-models/#key-features","level":2,"title":"Key features","text":"<ul> <li>Typed attributes with defaults</li> <li>Hash key and range key support</li> <li>Required fields with <code>null=False</code></li> <li>Convert to/from dict</li> <li>TTL (auto-delete items after expiration)</li> </ul>","path":["Models"],"tags":[]},{"location":"guides/01-models/#getting-started","level":2,"title":"Getting started","text":"","path":["Models"],"tags":[]},{"location":"guides/01-models/#basic-model","level":3,"title":"Basic model","text":"basic_model.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import BooleanAttribute, NumberAttribute, StringAttribute\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    sk = StringAttribute(range_key=True)\n    name = StringAttribute()\n    age = NumberAttribute(default=0)\n    active = BooleanAttribute(default=True)\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#attribute-types","level":3,"title":"Attribute types","text":"Type DynamoDB type Python type <code>StringAttribute</code> S str <code>NumberAttribute</code> N int, float <code>BooleanAttribute</code> BOOL bool <code>BinaryAttribute</code> B bytes <code>ListAttribute</code> L list <code>MapAttribute</code> M dict <code>TTLAttribute</code> N datetime <code>CompressedAttribute</code> S str","path":["Models"],"tags":[]},{"location":"guides/01-models/#keys","level":3,"title":"Keys","text":"<p>Every model needs at least a hash key (partition key):</p> <pre><code>class User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)  # Required\n</code></pre> <p>Add a range key (sort key) for composite keys:</p> <pre><code>class User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    sk = StringAttribute(range_key=True)  # Optional\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#defaults-and-required-fields","level":3,"title":"Defaults and required fields","text":"with_defaults.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import (\n    BooleanAttribute,\n    ListAttribute,\n    MapAttribute,\n    NumberAttribute,\n    StringAttribute,\n)\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    email = StringAttribute(null=False)  # Required field\n    name = StringAttribute(default=\"\")\n    age = NumberAttribute(default=0)\n    active = BooleanAttribute(default=True)\n    tags = ListAttribute(default=[])\n    settings = MapAttribute(default={})\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#advanced","level":2,"title":"Advanced","text":"","path":["Models"],"tags":[]},{"location":"guides/01-models/#meta-options","level":3,"title":"Meta options","text":"Option Type Default Description <code>table</code> str Required DynamoDB table name <code>region</code> str None AWS region <code>endpoint_url</code> str None Custom endpoint <code>skip_hooks</code> bool False Skip lifecycle hooks","path":["Models"],"tags":[]},{"location":"guides/01-models/#converting-to-dict","level":3,"title":"Converting to dict","text":"<pre><code>user = User(pk=\"USER#123\", sk=\"PROFILE\", name=\"John\")\ndata = user.to_dict()\n# {'pk': 'USER#123', 'sk': 'PROFILE', 'name': 'John'}\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#creating-from-dict","level":3,"title":"Creating from dict","text":"<pre><code>data = {'pk': 'USER#123', 'sk': 'PROFILE', 'name': 'John'}\nuser = User.from_dict(data)\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#compressed-attributes","level":2,"title":"Compressed attributes","text":"<p>DynamoDB charges by item size. Large text fields eat up your budget and can hit the 400KB limit. <code>CompressedAttribute</code> solves this by compressing large text automatically.</p>","path":["Models"],"tags":[]},{"location":"guides/01-models/#why-use-compression","level":3,"title":"Why use compression?","text":"<ul> <li>Save money - Smaller items = lower storage and I/O costs</li> <li>Avoid limits - DynamoDB has a 400KB item size limit</li> <li>Transparent - Compression/decompression happens automatically</li> <li>Fast - Compression runs in Rust, not Python</li> </ul>","path":["Models"],"tags":[]},{"location":"guides/01-models/#basic-usage","level":3,"title":"Basic usage","text":"basic_compression.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import CompressedAttribute, StringAttribute\n\n\nclass Article(Model):\n    class Meta:\n        table = \"articles\"\n\n    pk = StringAttribute(hash_key=True)\n    content = CompressedAttribute()  # Auto-compresses large text\n\n\n# Create an article with large content\narticle = Article(\n    pk=\"ARTICLE#123\",\n    content=\"This is a very long article...\" * 1000,\n)\narticle.save()\n\n# When you read it back, it's automatically decompressed\nloaded = Article.get(pk=\"ARTICLE#123\")\nprint(loaded.content)  # Original text, not compressed\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#compression-algorithms","level":3,"title":"Compression algorithms","text":"<p>Three algorithms are available:</p> Algorithm Best for Trade-off <code>Zstd</code> Most cases (default) Best compression ratio <code>Lz4</code> High throughput Fastest, larger output <code>Gzip</code> Compatibility Good balance algorithm_options.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import CompressedAttribute, CompressionAlgorithm, StringAttribute\n\n\nclass Document(Model):\n    class Meta:\n        table = \"documents\"\n\n    pk = StringAttribute(hash_key=True)\n\n    # Best compression ratio (default)\n    body = CompressedAttribute(algorithm=CompressionAlgorithm.Zstd)\n\n    # Fastest compression/decompression\n    logs = CompressedAttribute(algorithm=CompressionAlgorithm.Lz4)\n\n    # Good balance, widely compatible\n    metadata = CompressedAttribute(algorithm=CompressionAlgorithm.Gzip)\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#compression-options","level":3,"title":"Compression options","text":"Parameter Type Default Description <code>algorithm</code> CompressionAlgorithm Zstd Compression algorithm <code>level</code> int 3 (zstd), 6 (gzip) Higher = better compression, slower <code>min_size</code> int 100 Only compress if &gt;= this many bytes <code>threshold</code> float 0.9 Only compress if ratio is below this compression_options.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import CompressedAttribute, StringAttribute\n\n\nclass LogEntry(Model):\n    class Meta:\n        table = \"logs\"\n\n    pk = StringAttribute(hash_key=True)\n\n    # Custom compression settings\n    message = CompressedAttribute(\n        level=10,  # Higher level = better compression, slower\n        min_size=200,  # Only compress if &gt;= 200 bytes\n        threshold=0.8,  # Only compress if saves at least 20%\n    )\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#how-it-works","level":3,"title":"How it works","text":"<ol> <li>When you save, the attribute checks if the value is large enough (<code>min_size</code>)</li> <li>It compresses the data and checks if it's worth it (<code>threshold</code>)</li> <li>If compression helps, it stores the compressed data with a prefix like <code>ZSTD:</code></li> <li>When you read, it detects the prefix and decompresses automatically</li> </ol> <p>Small values (under <code>min_size</code>) are stored as-is. This avoids overhead for short strings.</p>","path":["Models"],"tags":[]},{"location":"guides/01-models/#storage-format","level":3,"title":"Storage format","text":"<p>Compressed values are stored as base64-encoded strings with a prefix:</p> <ul> <li><code>ZSTD:abc123...</code> - Zstd compressed</li> <li><code>LZ4:abc123...</code> - LZ4 compressed  </li> <li><code>GZIP:abc123...</code> - Gzip compressed</li> </ul> <p>Values without a prefix are stored uncompressed.</p> <p>Tip</p> <p>You can change the algorithm later. Old items will still decompress correctly because the prefix tells pydynox which algorithm was used.</p>","path":["Models"],"tags":[]},{"location":"guides/01-models/#ttl-time-to-live","level":2,"title":"TTL (Time-To-Live)","text":"<p>Auto-delete items after a certain time. DynamoDB handles the deletion for you - no cron jobs needed.</p>","path":["Models"],"tags":[]},{"location":"guides/01-models/#what-is-ttl","level":3,"title":"What is TTL?","text":"<p>TTL lets you set an expiration time on items. When the time passes, DynamoDB automatically deletes the item. This is useful for:</p> <ul> <li>Session data - Delete sessions after they expire</li> <li>Temporary tokens - Clean up verification codes, password reset tokens</li> <li>Cache entries - Remove stale cached data</li> <li>Audit logs - Keep logs for 90 days, then delete</li> </ul>","path":["Models"],"tags":[]},{"location":"guides/01-models/#basic-ttl-usage","level":3,"title":"Basic TTL usage","text":"<p>Add a <code>TTLAttribute</code> to your model and use <code>ExpiresIn</code> to set expiration times:</p> basic_ttl.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import ExpiresIn, StringAttribute, TTLAttribute\n\n\nclass Session(Model):\n    class Meta:\n        table = \"sessions\"\n\n    pk = StringAttribute(hash_key=True)\n    user_id = StringAttribute()\n    expires_at = TTLAttribute()\n\n\n# Create session that expires in 1 hour\nsession = Session(\n    pk=\"SESSION#123\",\n    user_id=\"USER#456\",\n    expires_at=ExpiresIn.hours(1),\n)\nsession.save()\n\n# Check if expired\nif session.is_expired:\n    print(\"Session expired\")\n\n# Get time remaining\nremaining = session.expires_in\nif remaining:\n    print(f\"Expires in {remaining.total_seconds()} seconds\")\n\n# Extend by 1 hour\nsession.extend_ttl(ExpiresIn.hours(1))\n</code></pre> <p>The <code>ExpiresIn</code> helper makes it easy to set expiration times without doing datetime math:</p> Method Description <code>ExpiresIn.seconds(n)</code> n seconds from now <code>ExpiresIn.minutes(n)</code> n minutes from now <code>ExpiresIn.hours(n)</code> n hours from now <code>ExpiresIn.days(n)</code> n days from now <code>ExpiresIn.weeks(n)</code> n weeks from now","path":["Models"],"tags":[]},{"location":"guides/01-models/#checking-expiration","level":3,"title":"Checking expiration","text":"<p>You can check if an item has expired without waiting for DynamoDB to delete it:</p> <pre><code>session = Session.get(pk=\"SESSION#123\")\n\nif session.is_expired:\n    print(\"Session expired, please log in again\")\n</code></pre> <p>Get the time remaining:</p> <pre><code>remaining = session.expires_in\nif remaining:\n    print(f\"Session expires in {remaining.total_seconds()} seconds\")\nelse:\n    print(\"Session already expired\")\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#extending-ttl","level":3,"title":"Extending TTL","text":"<p>Extend the expiration time for active sessions:</p> <pre><code>session = Session.get(pk=\"SESSION#123\")\nif session and not session.is_expired:\n    session.extend_ttl(ExpiresIn.hours(1))  # Add 1 more hour\n</code></pre> <p>This updates both the local object and DynamoDB.</p>","path":["Models"],"tags":[]},{"location":"guides/01-models/#session-management-example","level":3,"title":"Session management example","text":"<p>Here's a complete example of session management with TTL:</p> session_example.py <pre><code>from uuid import uuid4\n\nfrom pydynox import Model\nfrom pydynox.attributes import ExpiresIn, StringAttribute, TTLAttribute\n\n\nclass Session(Model):\n    class Meta:\n        table = \"sessions\"\n\n    pk = StringAttribute(hash_key=True)\n    user_id = StringAttribute()\n    expires_at = TTLAttribute()\n\n\ndef create_session(user_id: str) -&gt; Session:\n    \"\"\"Create a session that expires in 24 hours.\"\"\"\n    session = Session(\n        pk=f\"SESSION#{uuid4()}\",\n        user_id=user_id,\n        expires_at=ExpiresIn.hours(24),\n    )\n    session.save()\n    return session\n\n\ndef validate_session(session_id: str) -&gt; bool:\n    \"\"\"Check if session is valid.\"\"\"\n    session = Session.get(pk=session_id)\n    if not session or session.is_expired:\n        return False\n    return True\n\n\ndef refresh_session(session_id: str) -&gt; None:\n    \"\"\"Extend session by 24 hours.\"\"\"\n    session = Session.get(pk=session_id)\n    if session and not session.is_expired:\n        session.extend_ttl(ExpiresIn.hours(24))\n</code></pre>","path":["Models"],"tags":[]},{"location":"guides/01-models/#how-dynamodb-ttl-works","level":3,"title":"How DynamoDB TTL works","text":"<ol> <li> <p>TTL is stored as epoch timestamp - The <code>TTLAttribute</code> converts datetime to Unix timestamp (seconds since 1970)</p> </li> <li> <p>Deletion is not instant - DynamoDB checks TTL every few minutes. Expired items are usually deleted within 48 hours, but often much faster.</p> </li> <li> <p>You can still read expired items - Until DynamoDB deletes them, expired items are still in the table. That's why <code>is_expired</code> is useful.</p> </li> <li> <p>Deletions are free - TTL deletions don't count toward your write capacity. This makes TTL great for cleanup.</p> </li> <li> <p>Enable TTL on the table - You need to enable TTL in DynamoDB console or via API. The attribute name must match your <code>TTLAttribute</code> field name.</p> </li> </ol>","path":["Models"],"tags":[]},{"location":"guides/01-models/#enabling-ttl-on-your-table","level":3,"title":"Enabling TTL on your table","text":"<p>TTL must be enabled on the DynamoDB table. You can do this in the AWS Console:</p> <ol> <li>Go to your table in DynamoDB console</li> <li>Click \"Additional settings\" tab</li> <li>Find \"Time to Live (TTL)\" section</li> <li>Click \"Enable\"</li> <li>Enter the attribute name (e.g., <code>expires_at</code>)</li> </ol> <p>Or via AWS CLI:</p> <pre><code>aws dynamodb update-time-to-live \\\n    --table-name sessions \\\n    --time-to-live-specification \"Enabled=true, AttributeName=expires_at\"\n</code></pre> <p>Warning</p> <p>The attribute name in DynamoDB must match your <code>TTLAttribute</code> field name exactly. If your model has <code>expires_at = TTLAttribute()</code>, use <code>expires_at</code> when enabling TTL.</p>","path":["Models"],"tags":[]},{"location":"guides/01-models/#ttl-best-practices","level":3,"title":"TTL best practices","text":"<ol> <li> <p>Always check <code>is_expired</code> - Don't assume items are deleted immediately after expiration</p> </li> <li> <p>Use appropriate TTL values - Too short and you'll have issues; too long and you're storing unnecessary data</p> </li> <li> <p>Consider time zones - <code>ExpiresIn</code> uses UTC. If your users are in different time zones, be careful with \"end of day\" logic</p> </li> <li> <p>Monitor deletions - DynamoDB publishes TTL deletion metrics to CloudWatch</p> </li> </ol>","path":["Models"],"tags":[]},{"location":"guides/03-crud/","level":1,"title":"CRUD operations","text":"<p>Basic create, read, update, delete operations. These are the most common operations you'll do with DynamoDB.</p>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#key-features","level":2,"title":"Key features","text":"<ul> <li><code>save()</code> to create or replace items</li> <li><code>get()</code> to read by key</li> <li><code>update()</code> for partial updates</li> <li><code>delete()</code> to remove items</li> </ul>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#getting-started","level":2,"title":"Getting started","text":"<p>Here's a complete example showing all CRUD operations:</p> crud_operations.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import NumberAttribute, StringAttribute\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    sk = StringAttribute(range_key=True)\n    name = StringAttribute()\n    age = NumberAttribute(default=0)\n\n\n# Create\nuser = User(pk=\"USER#123\", sk=\"PROFILE\", name=\"John\", age=30)\nuser.save()\n\n# Read\nuser = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nif user:\n    print(user.name)  # John\n\n# Update - full\nuser.name = \"Jane\"\nuser.save()\n\n# Update - partial\nuser.update(name=\"Jane\", age=31)\n\n# Delete\nuser.delete()\n</code></pre> <p>Let's break down each operation.</p>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#create","level":3,"title":"Create","text":"<p>To create a new item, instantiate your model and call <code>save()</code>:</p> <pre><code>user = User(pk=\"USER#123\", sk=\"PROFILE\", name=\"John\", age=30)\nuser.save()\n</code></pre> <p>If an item with the same key already exists, <code>save()</code> replaces it completely. This is how DynamoDB works - there's no separate \"create\" vs \"update\" at the API level.</p>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#read","level":3,"title":"Read","text":"<p>To get an item by its key, use the class method <code>get()</code>:</p> <pre><code>user = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nif user:\n    print(user.name)\nelse:\n    print(\"User not found\")\n</code></pre> <p><code>get()</code> returns <code>None</code> if the item doesn't exist. Always check for <code>None</code> before using the result.</p> <p>If your table has only a hash key (no range key), you only need to pass the hash key:</p> <pre><code>user = User.get(pk=\"USER#123\")\n</code></pre>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#update","level":3,"title":"Update","text":"<p>There are two ways to update an item:</p> <p>Full update with save(): Change attributes and call <code>save()</code>. This replaces the entire item:</p> <pre><code>user = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nuser.name = \"Jane\"\nuser.age = 31\nuser.save()\n</code></pre> <p>Partial update with update(): Update specific fields without touching others:</p> <pre><code>user = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nuser.update(name=\"Jane\", age=31)\n</code></pre> <p>The difference matters when you have many attributes. With <code>save()</code>, you send all attributes to DynamoDB. With <code>update()</code>, you only send the changed ones.</p> <p><code>update()</code> also updates the local object, so <code>user.name</code> is <code>\"Jane\"</code> after the call.</p>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#delete","level":3,"title":"Delete","text":"<p>To delete an item, call <code>delete()</code> on an instance:</p> <pre><code>user = User.get(pk=\"USER#123\", sk=\"PROFILE\")\nuser.delete()\n</code></pre> <p>After deletion, the object still exists in Python, but the item is gone from DynamoDB.</p>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#advanced","level":2,"title":"Advanced","text":"","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#skipping-hooks","level":3,"title":"Skipping hooks","text":"<p>If you have lifecycle hooks but want to skip them for a specific operation:</p> <pre><code>user.save(skip_hooks=True)\nuser.delete(skip_hooks=True)\nuser.update(skip_hooks=True, name=\"Jane\")\n</code></pre> <p>This is useful for:</p> <ul> <li>Data migrations where validation might fail on old data</li> <li>Bulk operations where you want maximum speed</li> <li>Fixing bad data that wouldn't pass validation</li> </ul> <p>You can also disable hooks for all operations on a model:</p> <pre><code>class User(Model):\n    class Meta:\n        table = \"users\"\n        skip_hooks = True  # All hooks disabled by default\n</code></pre> <p>Warning</p> <p>Be careful when skipping hooks. If you have validation in <code>before_save</code>, skipping it means invalid data can be saved to DynamoDB.</p>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#error-handling","level":3,"title":"Error handling","text":"<p>DynamoDB operations can fail for various reasons. Common errors:</p> Error Cause <code>ResourceNotFoundException</code> Table doesn't exist <code>ProvisionedThroughputExceededException</code> Exceeded capacity <code>ValidationException</code> Invalid data (item too large, etc.) <p>Wrap operations in try/except if you need to handle errors:</p> <pre><code>try:\n    user.save()\nexcept Exception as e:\n    print(f\"Failed to save: {e}\")\n</code></pre>","path":["CRUD operations"],"tags":[]},{"location":"guides/03-crud/#conditional-operations","level":3,"title":"Conditional operations","text":"<p>DynamoDB supports conditional writes - only save if a condition is met. This is useful for optimistic locking and preventing overwrites.</p> <p>Note</p> <p>Conditional operations are planned but not yet implemented in pydynox.</p>","path":["CRUD operations"],"tags":[]},{"location":"guides/04-batch/","level":1,"title":"Batch operations","text":"<p>Work with multiple items at once. Instead of making 100 separate API calls, batch operations let you send items in groups of 25 (the DynamoDB limit).</p>","path":["Batch operations"],"tags":[]},{"location":"guides/04-batch/#key-features","level":2,"title":"Key features","text":"<ul> <li>Auto-batching in groups of 25</li> <li>Automatic retry for failed items</li> <li>Mix puts and deletes in one batch</li> </ul>","path":["Batch operations"],"tags":[]},{"location":"guides/04-batch/#getting-started","level":2,"title":"Getting started","text":"<p>Use <code>BatchWriter</code> to save or delete many items. The batch writer handles all the complexity for you: it groups items into batches, sends them to DynamoDB, and retries any items that fail.</p> batch_write.py <pre><code>from pydynox import BatchWriter, DynamoDBClient\n\nclient = DynamoDBClient()\n\n# Batch write - items are sent in groups of 25\nwith BatchWriter(client, \"users\") as batch:\n    for i in range(100):\n        batch.put({\"pk\": f\"USER#{i}\", \"name\": f\"User {i}\"})\n\n# Mix puts and deletes\nwith BatchWriter(client, \"users\") as batch:\n    batch.put({\"pk\": \"USER#1\", \"name\": \"John\"})\n    batch.put({\"pk\": \"USER#2\", \"name\": \"Jane\"})\n    batch.delete({\"pk\": \"USER#3\"})\n</code></pre> <p>When you use <code>BatchWriter</code> as a context manager (with <code>with</code>), it automatically flushes any remaining items when the block ends. This means you don't have to worry about items being left unsent.</p> <p>The batch writer accepts two types of operations:</p> <ul> <li><code>batch.put(item)</code> - Add or replace an item</li> <li><code>batch.delete(key)</code> - Remove an item by its key</li> </ul> <p>You can mix both operations in the same batch. DynamoDB processes them in any order, so don't rely on a specific sequence.</p>","path":["Batch operations"],"tags":[]},{"location":"guides/04-batch/#advanced","level":2,"title":"Advanced","text":"","path":["Batch operations"],"tags":[]},{"location":"guides/04-batch/#manual-flush","level":3,"title":"Manual flush","text":"<p>By default, the batch writer sends items to DynamoDB when it has 25 items ready, or when the context exits. If you want to send items earlier, call <code>flush()</code>:</p> <pre><code>with BatchWriter(client, \"users\") as batch:\n    for i in range(100):\n        batch.put({\"pk\": f\"USER#{i}\", \"name\": f\"User {i}\"})\n\n        # Flush every 50 items instead of waiting\n        if i % 50 == 0:\n            batch.flush()\n</code></pre> <p>This is useful when you want to see progress during long-running operations, or when you need to free up memory.</p>","path":["Batch operations"],"tags":[]},{"location":"guides/04-batch/#error-handling","level":3,"title":"Error handling","text":"<p>DynamoDB sometimes can't process all items in a batch. This happens when you hit throughput limits or when there's a temporary service issue.</p> <p>The batch writer automatically retries failed items with exponential backoff. If items still fail after all retries, an exception is raised when the context exits:</p> <pre><code>try:\n    with BatchWriter(client, \"users\") as batch:\n        batch.put({\"pk\": \"USER#1\", \"name\": \"John\"})\nexcept Exception as e:\n    print(f\"Some items failed: {e}\")\n</code></pre> <p>Tip</p> <p>If you're seeing frequent failures, consider using rate limiting to stay within your provisioned capacity.</p>","path":["Batch operations"],"tags":[]},{"location":"guides/04-batch/#performance-tips","level":3,"title":"Performance tips","text":"<ol> <li> <p>Use batch operations for bulk work - If you're saving more than a few items, batching is faster than individual <code>put_item</code> calls.</p> </li> <li> <p>Don't batch single items - For one or two items, use regular <code>put_item</code>. The overhead of batching isn't worth it.</p> </li> <li> <p>Consider rate limiting - If you're writing a lot of data, combine batch operations with rate limiting to avoid throttling.</p> </li> </ol>","path":["Batch operations"],"tags":[]},{"location":"guides/05-transactions/","level":1,"title":"Transactions","text":"<p>Run multiple operations that succeed or fail together. If any operation fails, DynamoDB rolls back all changes automatically.</p>","path":["Transactions"],"tags":[]},{"location":"guides/05-transactions/#key-features","level":2,"title":"Key features","text":"<ul> <li>All-or-nothing operations</li> <li>Put, delete, and update in one transaction</li> <li>Max 100 items per transaction</li> </ul>","path":["Transactions"],"tags":[]},{"location":"guides/05-transactions/#getting-started","level":2,"title":"Getting started","text":"<p>Transactions are useful when you need to update related data atomically. For example, when creating an order, you might want to:</p> <ol> <li>Create the order record</li> <li>Update the user's order count</li> <li>Decrease inventory</li> </ol> <p>If any of these fails, you don't want partial data. Transactions guarantee all operations succeed or none do.</p> basic_transaction.py <pre><code>from pydynox import DynamoDBClient, Transaction\n\nclient = DynamoDBClient()\n\n# All operations succeed or fail together\nwith Transaction(client) as tx:\n    tx.put(\"users\", {\"pk\": \"USER#1\", \"name\": \"John\"})\n    tx.put(\"orders\", {\"pk\": \"ORDER#1\", \"user\": \"USER#1\"})\n    tx.delete(\"temp\", {\"pk\": \"TEMP#1\"})\n</code></pre> <p>When you use <code>Transaction</code> as a context manager, it automatically commits when the block ends. If an exception occurs inside the block, the transaction is not committed.</p>","path":["Transactions"],"tags":[]},{"location":"guides/05-transactions/#advanced","level":2,"title":"Advanced","text":"","path":["Transactions"],"tags":[]},{"location":"guides/05-transactions/#transaction-operations","level":3,"title":"Transaction operations","text":"<p>You can mix different operations in one transaction:</p> Operation Description <code>tx.put(table, item)</code> Add or replace an item <code>tx.delete(table, key)</code> Remove an item <code>tx.update(table, key, updates)</code> Update specific attributes <pre><code>with Transaction(client) as tx:\n    # Create new item\n    tx.put(\"users\", {\"pk\": \"USER#1\", \"name\": \"John\"})\n\n    # Update existing item\n    tx.update(\"users\", {\"pk\": \"USER#2\"}, {\"order_count\": 5})\n\n    # Delete item\n    tx.delete(\"temp\", {\"pk\": \"TEMP#1\"})\n</code></pre>","path":["Transactions"],"tags":[]},{"location":"guides/05-transactions/#limits","level":3,"title":"Limits","text":"<p>DynamoDB transactions have limits you should know:</p> Limit Value Max items 100 Max size 4 MB total Region All items must be in the same region <p>If you exceed these limits, the transaction fails before any operation runs.</p>","path":["Transactions"],"tags":[]},{"location":"guides/05-transactions/#when-to-use-transactions","level":3,"title":"When to use transactions","text":"<p>Use transactions when:</p> <ul> <li>You need all-or-nothing behavior</li> <li>You're updating related data that must stay consistent</li> <li>You need to check conditions before writing (like \"only update if version matches\")</li> </ul> <p>Don't use transactions for:</p> <ul> <li>Simple single-item operations (just use <code>save()</code>)</li> <li>High-throughput batch writes (use <code>BatchWriter</code> instead - it's faster)</li> <li>Operations that can tolerate partial success</li> </ul> <p>Tip</p> <p>Transactions cost twice as much as regular operations because DynamoDB does extra work to guarantee atomicity. Use them only when you need the guarantee.</p>","path":["Transactions"],"tags":[]},{"location":"guides/05-transactions/#error-handling","level":3,"title":"Error handling","text":"<p>If a transaction fails, DynamoDB returns an error and no changes are made:</p> <pre><code>try:\n    with Transaction(client) as tx:\n        tx.put(\"users\", {\"pk\": \"USER#1\", \"name\": \"John\"})\n        tx.put(\"orders\", {\"pk\": \"ORDER#1\", \"user\": \"USER#1\"})\nexcept Exception as e:\n    print(f\"Transaction failed: {e}\")\n    # No changes were made to either table\n</code></pre> <p>Common reasons for transaction failures:</p> <ul> <li>Item size exceeds 400 KB</li> <li>Total transaction size exceeds 4 MB</li> <li>More than 100 items</li> <li>Condition check failed</li> <li>Throughput exceeded</li> </ul>","path":["Transactions"],"tags":[]},{"location":"guides/06-rate-limiting/","level":1,"title":"Rate limiting","text":"<p>Control how fast you read and write to DynamoDB. Rate limiting helps you stay within your provisioned capacity and avoid throttling errors.</p>","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#key-features","level":2,"title":"Key features","text":"<ul> <li>Fixed rate for known workloads</li> <li>Adaptive rate that adjusts based on throttling</li> <li>Metrics to track usage</li> </ul>","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#getting-started","level":2,"title":"Getting started","text":"","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#why-rate-limit","level":3,"title":"Why rate limit?","text":"<p>DynamoDB charges for capacity units. When you exceed your provisioned capacity, DynamoDB throttles your requests - they fail with a <code>ProvisionedThroughputExceededException</code>.</p> <p>Rate limiting helps you:</p> <ul> <li>Stay within budget - Don't accidentally burn through capacity</li> <li>Avoid throttling - Smooth out traffic spikes</li> <li>Share fairly - Multiple processes can share capacity without fighting</li> </ul>","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#fixed-rate","level":3,"title":"Fixed rate","text":"<p>Use <code>FixedRate</code> when you know exactly how much capacity to use. The rate stays constant unless you change it.</p> fixed_rate.py <pre><code>from pydynox import DynamoDBClient\nfrom pydynox.rate_limit import FixedRate\n\n# Limit to 50 read capacity units per second\nclient = DynamoDBClient(rate_limit=FixedRate(rcu=50))\n\n# Limit both read and write\nclient = DynamoDBClient(rate_limit=FixedRate(rcu=50, wcu=25))\n\n# Allow bursts up to 200 RCU\nclient = DynamoDBClient(rate_limit=FixedRate(rcu=50, burst=200))\n</code></pre> <p><code>FixedRate</code> is good for:</p> <ul> <li>Batch jobs with predictable throughput</li> <li>Background processes that shouldn't use too much capacity</li> <li>Sharing capacity between multiple workers</li> </ul>","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#adaptive-rate","level":3,"title":"Adaptive rate","text":"<p>Use <code>AdaptiveRate</code> when you don't know the right rate, or when capacity varies. It automatically adjusts based on throttling feedback.</p> adaptive_rate.py <pre><code>from pydynox import DynamoDBClient\nfrom pydynox.rate_limit import AdaptiveRate\n\n# Set max capacity, it figures out the rest\nclient = DynamoDBClient(rate_limit=AdaptiveRate(max_rcu=100))\n\n# With write limit too\nclient = DynamoDBClient(rate_limit=AdaptiveRate(max_rcu=100, max_wcu=50))\n\n# With custom min (won't go below this)\nclient = DynamoDBClient(rate_limit=AdaptiveRate(max_rcu=100, min_rcu=10))\n</code></pre> <p>How adaptive rate works:</p> <ol> <li>Starts at 50% of max rate</li> <li>When throttled, reduces by 20%</li> <li>When no throttle for 10 seconds, increases by 10%</li> <li>Never goes below min or above max</li> </ol> <p><code>AdaptiveRate</code> is good for:</p> <ul> <li>Variable workloads</li> <li>Shared tables where capacity changes</li> <li>When you're not sure what rate to use</li> </ul>","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#advanced","level":2,"title":"Advanced","text":"","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#checking-metrics","level":3,"title":"Checking metrics","text":"<p>You can see how much capacity you've used and how many times you were throttled:</p> check_metrics.py <pre><code>from pydynox import DynamoDBClient\nfrom pydynox.rate_limit import FixedRate\n\nrate_limit = FixedRate(rcu=50, wcu=25)\nclient = DynamoDBClient(rate_limit=rate_limit)\n\n# After some operations...\nfor i in range(10):\n    client.put_item(\"users\", {\"pk\": f\"USER#{i}\", \"name\": f\"User {i}\"})\n\n# Check metrics\nprint(f\"RCU used: {rate_limit.consumed_rcu}\")\nprint(f\"WCU used: {rate_limit.consumed_wcu}\")\nprint(f\"Throttle count: {rate_limit.throttle_count}\")\n</code></pre> <p>This is useful for:</p> <ul> <li>Monitoring your application</li> <li>Tuning your rate limits</li> <li>Debugging throttling issues</li> </ul>","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#fixedrate-parameters","level":3,"title":"FixedRate parameters","text":"Parameter Type Default Description <code>rcu</code> int None Read capacity units per second <code>wcu</code> int None Write capacity units per second <code>burst</code> int None Burst capacity (defaults to rate value) <p>About burst: DynamoDB allows short bursts above your provisioned rate. If you set <code>burst=200</code> with <code>rcu=50</code>, you can temporarily read at 200 RCU, but you'll need to slow down afterward to stay within your average.</p>","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#adaptiverate-parameters","level":3,"title":"AdaptiveRate parameters","text":"Parameter Type Default Description <code>max_rcu</code> int Required Maximum RCU per second <code>max_wcu</code> int None Maximum WCU per second <code>min_rcu</code> int 1 Minimum RCU (won't go below this) <code>min_wcu</code> int 1 Minimum WCU (won't go below this)","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#when-to-use-each","level":3,"title":"When to use each","text":"Scenario Recommendation Known, steady workload FixedRate Variable workload AdaptiveRate Batch jobs FixedRate with high burst Shared capacity AdaptiveRate Multiple workers FixedRate, divide capacity by worker count","path":["Rate limiting"],"tags":[]},{"location":"guides/06-rate-limiting/#rate-limiting-with-batch-operations","level":3,"title":"Rate limiting with batch operations","text":"<p>Rate limiting works with batch operations too. The rate limiter tracks capacity used by each batch and waits if needed:</p> <pre><code>from pydynox import BatchWriter, DynamoDBClient\nfrom pydynox.rate_limit import FixedRate\n\nclient = DynamoDBClient(rate_limit=FixedRate(wcu=50))\n\nwith BatchWriter(client, \"users\") as batch:\n    for i in range(1000):\n        batch.put({\"pk\": f\"USER#{i}\", \"name\": f\"User {i}\"})\n    # Rate limiter ensures we don't exceed 50 WCU\n</code></pre> <p>Tip</p> <p>When doing bulk writes, combine rate limiting with batch operations. This gives you both efficiency (fewer API calls) and control (predictable throughput).</p>","path":["Rate limiting"],"tags":[]},{"location":"guides/07-hooks/","level":1,"title":"Lifecycle hooks","text":"<p>Run code before or after model operations. Hooks let you add validation, logging, or any custom logic without cluttering your main code.</p>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#key-features","level":2,"title":"Key features","text":"<ul> <li>Validation before save</li> <li>Logging after operations</li> <li>Data transformation</li> <li>Side effects like sending emails</li> </ul>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#getting-started","level":2,"title":"Getting started","text":"<p>Hooks are methods decorated with special decorators. When you call <code>save()</code>, <code>delete()</code>, or <code>update()</code>, pydynox automatically runs the matching hooks.</p>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#available-hooks","level":3,"title":"Available hooks","text":"Hook When it runs <code>@before_save</code> Before <code>save()</code> <code>@after_save</code> After <code>save()</code> <code>@before_delete</code> Before <code>delete()</code> <code>@after_delete</code> After <code>delete()</code> <code>@before_update</code> Before <code>update()</code> <code>@after_update</code> After <code>update()</code> <code>@after_load</code> After <code>get()</code> or query","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#basic-usage","level":3,"title":"Basic usage","text":"<p>Here's a common pattern: validate and normalize data before saving, then log after:</p> validation.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import StringAttribute\nfrom pydynox.hooks import after_save, before_save\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    email = StringAttribute()\n    name = StringAttribute()\n\n    @before_save\n    def validate_email(self):\n        if not self.email or \"@\" not in self.email:\n            raise ValueError(\"Invalid email\")\n\n    @before_save\n    def normalize(self):\n        self.email = self.email.lower().strip()\n        self.name = self.name.strip()\n\n    @after_save\n    def log_save(self):\n        print(f\"Saved user: {self.pk}\")\n\n\n# Hooks run automatically\nuser = User(pk=\"USER#1\", email=\"JOHN@TEST.COM\", name=\"john doe\")\nuser.save()  # Validates, normalizes, then logs\n\n# Skip hooks if needed\nuser.save(skip_hooks=True)\n</code></pre> <p>In this example:</p> <ol> <li><code>validate_email</code> runs first and raises an error if the email is invalid</li> <li><code>normalize</code> runs next and cleans up the data</li> <li>The item is saved to DynamoDB</li> <li><code>log_save</code> runs last and prints a message</li> </ol> <p>If any <code>before_*</code> hook raises an exception, the operation stops and the item is not saved.</p>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#advanced","level":2,"title":"Advanced","text":"","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#multiple-hooks-of-the-same-type","level":3,"title":"Multiple hooks of the same type","text":"<p>You can have multiple hooks of the same type. They run in the order they're defined in the class:</p> <pre><code>class User(Model):\n    @before_save\n    def first_hook(self):\n        print(\"This runs first\")\n\n    @before_save\n    def second_hook(self):\n        print(\"This runs second\")\n</code></pre>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#all-hooks-example","level":3,"title":"All hooks example","text":"<p>Here's a model with all available hooks:</p> all_hooks.py <pre><code>from pydynox import Model\nfrom pydynox.attributes import StringAttribute\nfrom pydynox.hooks import (\n    after_delete,\n    after_load,\n    after_save,\n    after_update,\n    before_delete,\n    before_save,\n    before_update,\n)\n\n\nclass User(Model):\n    class Meta:\n        table = \"users\"\n\n    pk = StringAttribute(hash_key=True)\n    name = StringAttribute()\n\n    @before_save\n    def on_before_save(self):\n        print(\"Before save\")\n\n    @after_save\n    def on_after_save(self):\n        print(\"After save\")\n\n    @before_delete\n    def on_before_delete(self):\n        print(\"Before delete\")\n\n    @after_delete\n    def on_after_delete(self):\n        print(\"After delete\")\n\n    @before_update\n    def on_before_update(self):\n        print(\"Before update\")\n\n    @after_update\n    def on_after_update(self):\n        print(\"After update\")\n\n    @after_load\n    def on_after_load(self):\n        print(\"After load (get or query)\")\n</code></pre>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#skipping-hooks","level":3,"title":"Skipping hooks","text":"<p>Sometimes you need to bypass hooks. For example, during data migration or when fixing bad data.</p> <p>Skip hooks for a single operation:</p> <pre><code>user.save(skip_hooks=True)\nuser.delete(skip_hooks=True)\nuser.update(skip_hooks=True, name=\"Jane\")\n</code></pre> <p>Or disable hooks for all operations on a model:</p> <pre><code>class User(Model):\n    class Meta:\n        table = \"users\"\n        skip_hooks = True  # All hooks disabled by default\n</code></pre> <p>Warning</p> <p>Be careful when skipping hooks. If you have validation in <code>before_save</code>, skipping it means invalid data can be saved.</p>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#common-patterns","level":3,"title":"Common patterns","text":"Pattern Hook Example Validation <code>@before_save</code> Check email format, required fields Normalization <code>@before_save</code> Lowercase email, trim whitespace Timestamps <code>@before_save</code> Set <code>updated_at</code> field Logging <code>@after_save</code> Log saved item ID Audit <code>@after_save</code> Write to audit table Cleanup <code>@after_delete</code> Delete related data, files Transformation <code>@after_load</code> Format dates, compute fields","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/07-hooks/#hooks-and-transactions","level":3,"title":"Hooks and transactions","text":"<p>Hooks run for each item in a transaction. If you're saving 10 items in a transaction, <code>before_save</code> runs 10 times.</p> <p>If a hook raises an exception, the entire transaction fails and nothing is saved.</p>","path":["Lifecycle hooks"],"tags":[]},{"location":"guides/08-pydantic/","level":1,"title":"Pydantic integration","text":"<p>Use Pydantic models with DynamoDB. If you already have Pydantic models in your application, you can add DynamoDB persistence without rewriting them.</p>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#key-features","level":2,"title":"Key features","text":"<ul> <li>Use existing Pydantic models</li> <li>Automatic validation</li> <li>Type coercion</li> <li>All pydynox methods available</li> </ul>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#getting-started","level":2,"title":"Getting started","text":"","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#installation","level":3,"title":"Installation","text":"<p>Install pydynox with Pydantic support:</p> <pre><code>pip install pydynox[pydantic]\n</code></pre>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#basic-usage","level":3,"title":"Basic usage","text":"<p>Use the <code>@dynamodb_model</code> decorator on a Pydantic model:</p> basic_pydantic.py <pre><code>from pydantic import BaseModel, EmailStr\nfrom pydynox.integrations.pydantic import dynamodb_model\n\n\n@dynamodb_model(table=\"users\", hash_key=\"pk\")\nclass User(BaseModel):\n    pk: str\n    name: str\n    email: EmailStr\n    age: int = 0\n\n\n# Pydantic validation works\nuser = User(pk=\"USER#1\", name=\"John\", email=\"john@test.com\")\nuser.save()\n\n# Get\nuser = User.get(pk=\"USER#1\")\nprint(user.email)\n</code></pre> <p>The decorator adds all pydynox methods to your model:</p> <ul> <li><code>save()</code> - Save to DynamoDB</li> <li><code>get()</code> - Get by key</li> <li><code>delete()</code> - Delete from DynamoDB</li> <li><code>update()</code> - Update specific fields</li> </ul> <p>Your Pydantic model works exactly as before - validation, serialization, and all other Pydantic features still work.</p>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#with-range-key","level":3,"title":"With range key","text":"<p>Add a range key for composite keys:</p> <pre><code>@dynamodb_model(table=\"users\", hash_key=\"pk\", range_key=\"sk\")\nclass User(BaseModel):\n    pk: str\n    sk: str\n    name: str\n</code></pre>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#pydantic-validation","level":3,"title":"Pydantic validation","text":"<p>All Pydantic validation works. Invalid data raises <code>ValidationError</code> before anything is saved:</p> <pre><code>from pydantic import BaseModel, EmailStr, Field\n\n@dynamodb_model(table=\"users\", hash_key=\"pk\")\nclass User(BaseModel):\n    pk: str\n    name: str = Field(min_length=1, max_length=100)\n    email: EmailStr\n    age: int = Field(ge=0, le=150)\n\n# This raises ValidationError - email is invalid\nuser = User(pk=\"USER#1\", name=\"\", email=\"not-an-email\", age=-1)\n</code></pre>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#advanced","level":2,"title":"Advanced","text":"","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#configuration-options","level":3,"title":"Configuration options","text":"<p>Pass extra options to the decorator:</p> <pre><code>@dynamodb_model(\n    table=\"users\",\n    hash_key=\"pk\",\n    range_key=\"sk\",\n    region=\"us-east-1\",\n    endpoint_url=\"http://localhost:8000\",  # For local dev\n)\nclass User(BaseModel):\n    pk: str\n    sk: str\n    name: str\n</code></pre> Option Type Description <code>table</code> str DynamoDB table name (required) <code>hash_key</code> str Field name for partition key (required) <code>range_key</code> str Field name for sort key (optional) <code>region</code> str AWS region (optional) <code>endpoint_url</code> str Custom endpoint (optional)","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#alternative-from_pydantic-function","level":3,"title":"Alternative: from_pydantic function","text":"<p>If you prefer not to use decorators, use <code>from_pydantic</code>:</p> <pre><code>from pydynox.integrations.pydantic import from_pydantic\n\nclass User(BaseModel):\n    pk: str\n    sk: str\n    name: str\n\nUserDB = from_pydantic(User, table=\"users\", hash_key=\"pk\", range_key=\"sk\")\nuser = UserDB(pk=\"USER#1\", sk=\"PROFILE\", name=\"John\")\nuser.save()\n</code></pre>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#why-use-pydantic-integration","level":3,"title":"Why use Pydantic integration?","text":"<p>Benefits of using Pydantic with pydynox:</p> <ul> <li>Validation - Pydantic validates data before it reaches DynamoDB</li> <li>Type coercion - Strings become ints, etc.</li> <li>IDE support - Better autocomplete than raw dicts</li> <li>Reuse models - Use the same models for API and database</li> <li>JSON Schema - Auto-generated schemas for documentation</li> </ul>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#using-pydantic-validators","level":3,"title":"Using Pydantic validators","text":"<p>Use Pydantic's <code>@field_validator</code> and <code>@model_validator</code> for validation:</p> <pre><code>from pydantic import BaseModel, field_validator, model_validator\n\n@dynamodb_model(table=\"users\", hash_key=\"pk\")\nclass User(BaseModel):\n    pk: str\n    email: str\n    name: str\n\n    @field_validator(\"email\")\n    @classmethod\n    def validate_email(cls, v: str) -&gt; str:\n        if \"@\" not in v:\n            raise ValueError(\"Invalid email\")\n        return v.lower()  # Also normalize\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def set_defaults(cls, data: dict) -&gt; dict:\n        # Add computed fields, defaults, etc.\n        return data\n</code></pre>","path":["Pydantic integration"],"tags":[]},{"location":"guides/08-pydantic/#ttl-with-pydantic","level":3,"title":"TTL with Pydantic","text":"<p>For TTL, use a datetime field:</p> <pre><code>from datetime import datetime, timedelta, timezone\n\n@dynamodb_model(table=\"sessions\", hash_key=\"pk\")\nclass Session(BaseModel):\n    pk: str\n    user_id: str\n    expires_at: datetime\n\n    @classmethod\n    def create(cls, user_id: str, hours: int = 24) -&gt; \"Session\":\n        return cls(\n            pk=f\"SESSION#{uuid4()}\",\n            user_id=user_id,\n            expires_at=datetime.now(timezone.utc) + timedelta(hours=hours),\n        )\n\n    @property\n    def is_expired(self) -&gt; bool:\n        return datetime.now(timezone.utc) &gt; self.expires_at\n</code></pre> <p>Note</p> <p>Remember to enable TTL on your DynamoDB table and set the attribute name to <code>expires_at</code>.</p>","path":["Pydantic integration"],"tags":[]},{"location":"guides/09-exceptions/","level":1,"title":"Exceptions","text":"<p>pydynox maps AWS SDK errors to Python exceptions. This makes error handling easier and more Pythonic.</p>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#key-features","level":2,"title":"Key features","text":"<ul> <li>Clear exception hierarchy</li> <li>Helpful error messages</li> <li>Maps AWS errors to specific types</li> <li>Base exception for catch-all handling</li> </ul>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#getting-started","level":2,"title":"Getting started","text":"","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#exception-hierarchy","level":3,"title":"Exception hierarchy","text":"<p>All pydynox exceptions inherit from <code>PydynoxError</code>. You can catch specific errors or use the base class:</p> Exception When it happens <code>PydynoxError</code> Base exception for all pydynox errors <code>TableNotFoundError</code> Table does not exist <code>TableAlreadyExistsError</code> Table already exists <code>ValidationError</code> Invalid input (bad key, wrong type, etc.) <code>ConditionCheckFailedError</code> Condition expression returned false <code>TransactionCanceledError</code> Transaction failed <code>ThrottlingError</code> Request rate too high <code>AccessDeniedError</code> IAM permission denied <code>CredentialsError</code> AWS credentials missing or invalid <code>SerializationError</code> Cannot convert data to/from DynamoDB format <code>ConnectionError</code> Cannot connect to DynamoDB","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#basic-error-handling","level":3,"title":"Basic error handling","text":"<p>Import exceptions from <code>pydynox.pydynox_core</code>:</p> handling_errors.py <pre><code>from pydynox import DynamoDBClient\nfrom pydynox.pydynox_core import (\n    PydynoxError,\n    TableNotFoundError,\n    ValidationError,\n    ConditionCheckFailedError,\n    ThrottlingError,\n    CredentialsError,\n    ConnectionError,\n)\n\n\ndef safe_get_item():\n    client = DynamoDBClient()\n\n    try:\n        item = client.get_item(\"users\", {\"pk\": \"USER#123\"})\n        return item\n    except TableNotFoundError:\n        print(\"Table does not exist\")\n    except CredentialsError:\n        print(\"Check your AWS credentials\")\n    except ConnectionError:\n        print(\"Cannot connect to DynamoDB\")\n    except PydynoxError as e:\n        print(f\"Something went wrong: {e}\")\n</code></pre>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#condition-check-errors","level":3,"title":"Condition check errors","text":"<p>When using conditional writes, catch <code>ConditionCheckFailedError</code>:</p> condition_check.py <pre><code>from pydynox import DynamoDBClient\nfrom pydynox.pydynox_core import ConditionCheckFailedError\n\n\ndef update_if_exists():\n    client = DynamoDBClient()\n\n    try:\n        client.update_item(\n            \"users\",\n            {\"pk\": \"USER#123\"},\n            updates={\"name\": \"John\"},\n            condition_expression=\"attribute_exists(pk)\",\n        )\n        print(\"Updated successfully\")\n    except ConditionCheckFailedError:\n        print(\"Item does not exist, cannot update\")\n</code></pre>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#advanced","level":2,"title":"Advanced","text":"","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#connection-errors","level":3,"title":"Connection errors","text":"<p><code>ConnectionError</code> happens when pydynox cannot reach DynamoDB. Common causes:</p> <ul> <li>DynamoDB Local is not running</li> <li>Wrong endpoint URL</li> <li>Network issues</li> <li>Firewall blocking the connection</li> </ul> <pre><code>from pydynox.pydynox_core import ConnectionError\n\ntry:\n    client = DynamoDBClient(endpoint_url=\"http://localhost:8000\")\n    client.ping()\nexcept ConnectionError:\n    print(\"Start DynamoDB Local first: docker run -p 8000:8000 amazon/dynamodb-local\")\n</code></pre>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#credential-errors","level":3,"title":"Credential errors","text":"<p><code>CredentialsError</code> happens when AWS credentials are missing or invalid:</p> <pre><code>from pydynox.pydynox_core import CredentialsError\n\ntry:\n    client = DynamoDBClient()\n    client.ping()\nexcept CredentialsError as e:\n    print(f\"Fix your credentials: {e}\")\n</code></pre> <p>Common causes: - No AWS credentials configured - Invalid access key or secret key - Expired session token - Wrong AWS profile name</p>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#throttling-errors","level":3,"title":"Throttling errors","text":"<p><code>ThrottlingError</code> happens when you exceed your table's capacity:</p> <pre><code>from pydynox.pydynox_core import ThrottlingError\nimport time\n\ndef save_with_retry(client, table, item, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            client.put_item(table, item)\n            return\n        except ThrottlingError:\n            if attempt &lt; max_retries - 1:\n                wait_time = 2 ** attempt  # Exponential backoff\n                time.sleep(wait_time)\n            else:\n                raise\n</code></pre> <p>Tip</p> <p>Use the built-in rate limiting feature instead of manual retry logic. See the Rate limiting guide.</p>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#transaction-errors","level":3,"title":"Transaction errors","text":"<p><code>TransactionCanceledError</code> includes details about why the transaction failed:</p> <pre><code>from pydynox import Transaction\nfrom pydynox.pydynox_core import TransactionCanceledError\n\ntry:\n    with Transaction() as tx:\n        tx.put(\"accounts\", {\"pk\": \"ACC#1\", \"balance\": 100})\n        tx.update(\n            \"accounts\",\n            {\"pk\": \"ACC#2\"},\n            updates={\"balance\": 200},\n            condition_expression=\"attribute_exists(pk)\",\n        )\nexcept TransactionCanceledError as e:\n    print(f\"Transaction failed: {e}\")\n    # e.g., \"Transaction was canceled: Condition check failed\"\n</code></pre>","path":["Exceptions"],"tags":[]},{"location":"guides/09-exceptions/#best-practices","level":3,"title":"Best practices","text":"<ol> <li> <p>Catch specific exceptions first - Put specific handlers before the base <code>PydynoxError</code></p> </li> <li> <p>Log the full error - Exception messages include useful details from AWS</p> </li> <li> <p>Use retry for throttling - Or better, use rate limiting to avoid throttling</p> </li> <li> <p>Check credentials early - Call <code>client.ping()</code> at startup to catch credential issues</p> </li> <li> <p>Handle connection errors gracefully - Especially in Lambda where cold starts can cause timeouts</p> </li> </ol>","path":["Exceptions"],"tags":[]},{"location":"guides/10-tables/","level":1,"title":"Table operations","text":"<p>Create, check, and delete DynamoDB tables programmatically.</p>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#key-features","level":2,"title":"Key features","text":"<ul> <li>Create tables with hash key and optional range key</li> <li>On-demand or provisioned billing</li> <li>Customer managed encryption (KMS)</li> <li>Wait for table to become active</li> <li>Check if table exists</li> </ul>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#getting-started","level":2,"title":"Getting started","text":"","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#create-a-table","level":3,"title":"Create a table","text":"<p>Use <code>create_table()</code> to create a new DynamoDB table:</p> create_table.py <pre><code>from pydynox import DynamoDBClient\n\n\ndef create_users_table():\n    client = DynamoDBClient()\n\n    # Simple table with hash key only\n    client.create_table(\n        \"users\",\n        hash_key=(\"pk\", \"S\"),\n        wait=True,  # Wait for table to be ready\n    )\n\n\ndef create_orders_table():\n    client = DynamoDBClient()\n\n    # Table with hash key and range key\n    client.create_table(\n        \"orders\",\n        hash_key=(\"pk\", \"S\"),\n        range_key=(\"sk\", \"S\"),\n        wait=True,\n    )\n</code></pre> <p>The <code>hash_key</code> and <code>range_key</code> are tuples of <code>(attribute_name, attribute_type)</code>. Attribute types:</p> Type Description <code>\"S\"</code> String <code>\"N\"</code> Number <code>\"B\"</code> Binary","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#check-if-table-exists","level":3,"title":"Check if table exists","text":"<p>Before creating a table, check if it already exists:</p> <pre><code>client = DynamoDBClient()\n\nif not client.table_exists(\"users\"):\n    client.create_table(\"users\", hash_key=(\"pk\", \"S\"), wait=True)\n</code></pre>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#delete-a-table","level":3,"title":"Delete a table","text":"<pre><code>client = DynamoDBClient()\nclient.delete_table(\"users\")\n</code></pre> <p>Warning</p> <p>This permanently deletes the table and all its data. There is no confirmation prompt.</p>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#advanced","level":2,"title":"Advanced","text":"","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#billing-modes","level":3,"title":"Billing modes","text":"<p>DynamoDB offers two billing modes:</p> Mode Best for Cost <code>PAY_PER_REQUEST</code> Unpredictable traffic Pay per read/write <code>PROVISIONED</code> Steady traffic Fixed monthly cost <p>On-demand (PAY_PER_REQUEST) is the default. For provisioned capacity:</p> table_options.py <pre><code>from pydynox import DynamoDBClient\n\n\ndef create_provisioned_table():\n    client = DynamoDBClient()\n\n    # Provisioned capacity (fixed cost, predictable performance)\n    client.create_table(\n        \"high_traffic_table\",\n        hash_key=(\"pk\", \"S\"),\n        billing_mode=\"PROVISIONED\",\n        read_capacity=100,\n        write_capacity=50,\n        wait=True,\n    )\n\n\ndef create_encrypted_table():\n    client = DynamoDBClient()\n\n    # Customer managed KMS encryption\n    client.create_table(\n        \"sensitive_data\",\n        hash_key=(\"pk\", \"S\"),\n        encryption=\"CUSTOMER_MANAGED\",\n        kms_key_id=\"arn:aws:kms:us-east-1:123456789:key/abc-123\",\n        wait=True,\n    )\n\n\ndef create_infrequent_access_table():\n    client = DynamoDBClient()\n\n    # Infrequent access class (cheaper storage, higher read cost)\n    client.create_table(\n        \"archive\",\n        hash_key=(\"pk\", \"S\"),\n        table_class=\"STANDARD_INFREQUENT_ACCESS\",\n        wait=True,\n    )\n</code></pre>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#table-class","level":3,"title":"Table class","text":"<p>Choose a storage class based on access patterns:</p> Class Best for <code>STANDARD</code> Frequently accessed data (default) <code>STANDARD_INFREQUENT_ACCESS</code> Data accessed less than once per month <p>Infrequent access costs less for storage but more for reads.</p>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#encryption","level":3,"title":"Encryption","text":"<p>DynamoDB encrypts all data at rest. You can choose who manages the encryption key:</p> Option Description <code>AWS_OWNED</code> AWS manages the key (default, free) <code>AWS_MANAGED</code> AWS KMS manages the key (costs extra) <code>CUSTOMER_MANAGED</code> You manage the key in KMS (full control) <p>For <code>CUSTOMER_MANAGED</code>, you must provide the KMS key ARN.</p>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#wait-for-table","level":3,"title":"Wait for table","text":"<p>Tables take a few seconds to create. Use <code>wait=True</code> to block until the table is ready:</p> <pre><code>client.create_table(\"users\", hash_key=(\"pk\", \"S\"), wait=True)\n# Table is now ready to use\n</code></pre> <p>Or wait separately:</p> <pre><code>client.create_table(\"users\", hash_key=(\"pk\", \"S\"))\n# Do other setup...\nclient.wait_for_table_active(\"users\", timeout_seconds=30)\n</code></pre>","path":["Table operations"],"tags":[]},{"location":"guides/10-tables/#create-table-parameters","level":3,"title":"Create table parameters","text":"Parameter Type Default Description <code>table_name</code> str Required Name of the table <code>hash_key</code> tuple Required (name, type) for partition key <code>range_key</code> tuple None (name, type) for sort key <code>billing_mode</code> str <code>\"PAY_PER_REQUEST\"</code> Billing mode <code>read_capacity</code> int 5 RCU (only for PROVISIONED) <code>write_capacity</code> int 5 WCU (only for PROVISIONED) <code>table_class</code> str <code>\"STANDARD\"</code> Storage class <code>encryption</code> str <code>\"AWS_OWNED\"</code> Encryption type <code>kms_key_id</code> str None KMS key ARN <code>wait</code> bool False Wait for table to be active","path":["Table operations"],"tags":[]}]}